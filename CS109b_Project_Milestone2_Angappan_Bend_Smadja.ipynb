{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS109B - Project - Milestone 2\n",
    "\n",
    "### Sathish Angappan, Hannah Bend, Yohann Smadja\n",
    "\n",
    "In this notebook, we will extract our data from TMDb and transform it into train and test data.  At this point, the question we are attempting to answer is such: can a neural network be trained to recognize changes in movie poster trends decade over decade and accurately categorize a movie based on its poster?  Can it learn or account for the stylistic changes and trends throughout the decades as graphic design improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## setup\n",
    "import tmdbsimple as tmdb\n",
    "import requests\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmdb.API_KEY = '248bdba4be72e97807ddd482a6f8d508' #--Hannah's key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Decide on data to extract\n",
    "\n",
    "- Discussion about the imbalanced nature of the data and how you want to address it\n",
    "- Description of your data\n",
    "- What does your choice of Y look like?\n",
    "- Which features do you choose for X and why? \n",
    "- How do you sample your data, how many samples, and why?\n",
    "\n",
    "Our initial foray into the data revealed two key insights: 1) movies are classified as having multiple genres and 2) some genres are extremely niche.  To circumvent the latter, we are limiting our data universe to the three most common genres of Action, Comedy and Drama.  We will only extract from TMDb those movies whose list of genres include one or more of the three; unfortunately, this doesn't resolve for the first imbalance, as some movies will appear twice.  Take the 2016 movie Sing, for example, which TMDb categorizes first as an Animation, then a Comedy, then a Drama; Sing will appear in our initial data extract twice as a Comedy and again as a Drama.  We might address it simply by choosing the instance listed first, as TMDb seems to classify in descending order of relevance.\n",
    "\n",
    "We will have two downloads: one csv with metadata on the movie, and all of their corresponding posters.  Once we vectorize the poster images, we should be able to merge the two datasets on movie id.  Ultimately, our data will have the following for columns:\n",
    "    - movie id: TMDb's movie id\n",
    "    - title: the name of the movie\n",
    "    - release date: date of the movie's release\n",
    "    - release year: year of the movie's release \n",
    "    - popularity: a score of the movie's popularity, scale of 0-100\n",
    "    - vote average: average number of stars per rating, scale of 1-10\n",
    "    - genre id: the corresponding id of the movie's genre\n",
    "    - V1-##: vectorized columns of images, i.e. pixels\n",
    "    \n",
    "The genre id column will be our Y, or outcome variable, a factor with three possible values.  We chose the release date, release year, popularity and average vote as our X metadata variables, to be used in conjunction with the vectorized images.  Release year will allow us to train by decade; release data will allow us capture seasonality within the year (i.e. romance movies will trend upwards in February).  Popularity and average vote will help us capture any trends in genre popularity by/within decade.  For example, comedies might be more popular immediately following a stressful period such as the Cuban missile crisis.  Transforming the poster images into vectors will allow us to treat each \"pixel\" as a predictor and use an approach like PCA to identify the columns that comprise the most variability in the prediction. Lastly, title will not be used as a predictor but as an identifier.\n",
    "\n",
    "To begin with, we extracted the metadata for all movies of the three genres; we will narrow down this universe first by removing those movies that appear twice and secondly by setting our merge to a left outer join so that we only model on movies who have corresponding poster images.  Depending on the size of the dataset at that point, we may further reduce the number of observations by randomly sampling from each genre. Should we decide to go this route, we would first sample, then split into train and test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Extract Data\n",
    "\n",
    "### 2.1 Extract metadata in chunks\n",
    "\n",
    "Using code such as that below, we split up the extract by genre so as to not overload any one of our APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = []\n",
    "ids = []\n",
    "release_date = []\n",
    "popularity = []\n",
    "genre_ids = []\n",
    "vote_average = []\n",
    "release_year = []\n",
    "\n",
    "#Genre ID: \n",
    "comedy = 35\n",
    "discover = tmdb.Discover()\n",
    "\n",
    "for y in range(60):\n",
    "    response = discover.movie(page = 1, primary_release_year=2016-y, with_genres=comedy)\n",
    "    no_of_pages = discover.total_pages\n",
    "    for i in range(no_of_pages):\n",
    "        time.sleep(2)\n",
    "        response = discover.movie(page = i+1, primary_release_year=2016-y, with_genres=comedy)\n",
    "\n",
    "        for k, s in zip(range(len(discover.results)), discover.results):\n",
    "            title.append(s['title'])\n",
    "            ids.append(s['id'])\n",
    "            release_date.append(s['release_date'])\n",
    "            popularity.append(s['popularity'])\n",
    "            vote_average.append(s['vote_average'])\n",
    "            genre_ids.append(comedy)\n",
    "            release_year.append(2016-y)\n",
    "\n",
    "df_all_movies = pd.DataFrame({'title': title, 'ids': ids, 'release_date': release_date, 'release_year' : release_year, \n",
    "                               'popularity': popularity, 'genre_ids': genre_ids, 'vote_average': vote_average})\n",
    "\n",
    "len(df_all_movies)\n",
    "df_all_movies.to_csv('movies1960_2016_comedy.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Extract all posters for 1 movie\n",
    "\n",
    "We will create for loops of the code below to slowly download the posters for the movies in our dataset, likely limiting to just those categorized as English to reduce noise.  Given the posters all have different dimensions, we'll likely need to scale the images prior to vectorizing.  Per the lecture on CNN, we should be able to so while maintaining RBG values, which are key for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'tt0335266'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lostintranslation = tmdb.Movies(153)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several formats are available. We will select the same resolution of 500 for all of posters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'w92', u'w154', u'w185', u'w342', u'w500', u'w780', u'original']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_PATTERN = 'http://api.themoviedb.org/3/configuration?api_key={key}'\n",
    "url = CONFIG_PATTERN.format(key=tmdb.API_KEY)\n",
    "r = requests.get(url)\n",
    "config = r.json()\n",
    "\n",
    "base_url = config['images']['base_url']\n",
    "sizes = config['images']['poster_sizes']\n",
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://image.tmdb.org/t/p/w500/5T8VvuFTdaawKLJk34i69Utaw7o.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/en1D6ETmeeneBInKBwZ2xVjve8r.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/y3Fpvs5mYoD3ncPjkxYxwc5TRdU.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/oOmkcmzrMKfyMVWQHULJkmp8lY3.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/rWYr8wuIDYo7rUXW6uusRNZWBte.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/pe4W2mTLHMkBW59XB2EvQ6WCjRU.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/xmqRMnS8EVAOkrN5kD6iX4aq2eM.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/gNhfI18oPPqmR8RMFq6ciNo9FGy.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/ntzUnYFOvyEMCYW4FD2LuPrLPyM.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/bmMu4vtQ8zt78sa3uxvGxvrZtwR.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/7kkAVAoaVN0YLztG4FMrb5l7aRs.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/6tdPmesqRuJhcb6V3QTgxlX6Mog.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/xniSkkzLQBbqeHrJYAa6UHdD0Dg.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/in8sEXG554zQdm4aMnY9YXoaJuu.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/x9mlUUt7YNFHlcqPQycO1p3DX3A.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/kdOHC8MRr3bs7ec1TPhUM0SE4jS.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/mzFmV8sJQwUKmRoMT6OXhgauoeb.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/ersTnQHuxbWL94YvthcpdCrRCfJ.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/8U867iyo24WwOGxPiS2nM9EycNR.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/jDxmznbbXeVhRJaWdNGYkfof4ve.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/qtrw4Zc5J3NITcW0D64mATZxlsd.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/ith9jxbMvdUdiEq2aVdPI9JtsLR.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/dnZ8MtD66zA9ktVVUrolZD3PSBY.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/p5vu3QWMNX5yQmdhcAtAHnIqaY1.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/cpJ9491URvpRovBgtTBmodhKtDP.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/yGVhHMLgvPwXszMOxj1BLnInIZ7.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/bX2lDkopjtEijaFxdWDhQrH1AO4.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/AuKMcg3KZs3UIlL1KQt8XksgD1P.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/zLzPA3rJSMbKRopXz7kX1i2on12.jpg',\n",
       " 'http://image.tmdb.org/t/p/w500/1hyY5aJK6jsvn7fIPHmRz200tx6.jpg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download all the posters of \"Lost in Translation\"\n",
    "IMDBID = lostintranslation.info()[\"imdb_id\"]\n",
    "\n",
    "IMG_PATTERN = 'http://api.themoviedb.org/3/movie/{imdbid}/images?api_key={key}' \n",
    "r = requests.get(IMG_PATTERN.format(key=tmdb.API_KEY,imdbid=IMDBID))\n",
    "api_response = r.json()\n",
    "paths = api_response['posters']\n",
    "urls_posters = []\n",
    "for path in paths:\n",
    "    urls_posters.append(\"{0}{1}{2}\".format(base_url, u'w500', path['file_path'])) \n",
    "urls_posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moviename = \"lostintranslation\"\n",
    "local_path = 'C:\\\\Users\\\\yohan\\\\Dropbox\\\\Harvard\\\\CS109b\\\\Project\\\\Movie Posters\\\\'\n",
    "genre_id = 18 #drama\n",
    "k=1\n",
    "for url in urls_posters:\n",
    "    urllib.urlretrieve(url, local_path+moviename+\"_\"+str(k)+\"_\"+str(genre_id)+\".jpg\")\n",
    "    k+=1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Storage considerations\n",
    "\n",
    "We first noticed that most of the posters we downloaded for Lost in Translation are almost identical. Some have different color saturations, some have titles in different languages. Our dataframe of metadata contains 60,244 drama movies, 17,000 action movies and finally 40,000 comedies. If we assume we can download 30 posters per movie and that a poster is 100K big then just for drama we would end up with 60244 $\\times$ 30 $\\times$ 100 KB = 180 GB of movie posters. It seems more reasonable to only download one poster per movie. \n",
    "\n",
    "\n",
    "## 3. Image vectorization\n",
    "\n",
    "We use matplotlib to process RGB images and transform them in 'uint8' dataformat. 'u' stands for 'unassigned' (all values are positive), 'int' stands for integers (all values are integers) and finally 8 means there is only 8 bits of information. Hence all values are between 0 and 255.\n",
    "\n",
    "Each image is transformed into a 3-dimension matrix: Each pixel is represented by 3 values for the three additive primary colors, red, green and blue.\n",
    "\n",
    "Even though most posters have the same matrix size (750 $\\times$ 500 $\\times$ 3), it happens that some posters have a slightly different shape. We show below how to resize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 shape: (750L, 500L, 3L)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  5,   4,   2],\n",
       "        [  5,   4,   2],\n",
       "        [  4,   3,   0],\n",
       "        ..., \n",
       "        [  8,   4,   1],\n",
       "        [  8,   4,   1],\n",
       "        [  8,   4,   1]],\n",
       "\n",
       "       [[  5,   4,   2],\n",
       "        [  5,   4,   2],\n",
       "        [  4,   3,   0],\n",
       "        ..., \n",
       "        [  8,   4,   1],\n",
       "        [  8,   4,   1],\n",
       "        [  8,   4,   1]],\n",
       "\n",
       "       [[  4,   3,   1],\n",
       "        [  4,   3,   1],\n",
       "        [  4,   3,   0],\n",
       "        ..., \n",
       "        [  8,   4,   1],\n",
       "        [  8,   4,   1],\n",
       "        [  8,   4,   1]],\n",
       "\n",
       "       ..., \n",
       "       [[138,  58,  49],\n",
       "        [133,  53,  44],\n",
       "        [131,  51,  42],\n",
       "        ..., \n",
       "        [151,  65,  50],\n",
       "        [151,  65,  50],\n",
       "        [152,  66,  51]],\n",
       "\n",
       "       [[134,  54,  47],\n",
       "        [134,  54,  47],\n",
       "        [132,  52,  45],\n",
       "        ..., \n",
       "        [147,  64,  48],\n",
       "        [147,  64,  48],\n",
       "        [147,  64,  48]],\n",
       "\n",
       "       [[126,  46,  39],\n",
       "        [133,  53,  46],\n",
       "        [134,  54,  47],\n",
       "        ..., \n",
       "        [146,  65,  48],\n",
       "        [145,  64,  47],\n",
       "        [145,  64,  47]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# First poster\n",
    "img1 = mpimg.imread('C:\\\\Users\\\\yohan\\\\Dropbox\\\\Harvard\\\\CS109b\\\\Project\\\\Movie Posters\\\\lostintranslation_1_18.jpg')\n",
    "print \"Image 1 shape:\", img1.shape\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 2 shape: (739L, 500L, 3L)\n"
     ]
    }
   ],
   "source": [
    "# Second poster\n",
    "img2 = mpimg.imread('C:\\\\Users\\\\yohan\\\\Dropbox\\\\Harvard\\\\CS109b\\\\Project\\\\Movie Posters\\\\lostintranslation_2_18.jpg')\n",
    "print \"Image 2 shape:\", img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 2 new shape: (750L, 500L, 3L)\n"
     ]
    }
   ],
   "source": [
    "import scipy.misc\n",
    "\n",
    "img2_resized = scipy.misc.imresize(img2, (750,500), interp='bilinear', mode=None)\n",
    "print \"Image 2 new shape:\", img2_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
